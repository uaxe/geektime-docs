你好，我是徐昊，今天我们来继续学习AI时代的软件工程。

通过前面的学习，我们逐步认识了知识工程的整体框架，并且尝试用知识工程的视角重新理解软件工程，那么软件工程效率提升的问题，自然就转化成为构造知识传递效率更高的知识过程。

那么大语言模型（Large Language Model，LLM）能否让知识过程更高效呢？这就是今天我们要讨论的问题，因为这是将大语言模型（Large Language Model，LLM）应用到知识过程的前提条件。

## **LLM是革命性的迁移学习平台**

LLM是怎么帮助我们提取知识的呢？我们首先需要将 **LLM看作一种特殊的迁移学习（Transfer Learning）平台**。

迁移学习（Transfer Learning）是机器学习领域的一个重要概念，意思是将从一个问题（源任务）中学到的知识应用到另一个相关的问题（目标任务）上。即使两个任务不完全相同，一个任务中学到的特征、模式和知识也可以在另一个任务中发挥作用，从而提高学习效率和性能。比如，一个可以识别猫狗的计算机视觉AI，可以通过迁移学习训练成用来识别汽车的AI。

迁移学习在实际应用中非常重要，特别是在数据稀缺的情况下。例如，在深度学习中，训练一个从头开始的模型通常需要大量的标记数据和计算资源。通过迁移学习，我们可以利用在大型数据集上预训练的模型，然后将这些模型调整（fine-tune）到特定的、数据较少的任务上。

![](https://static001.geekbang.org/resource/image/48/de/48d5b74900de0bc19a5d12ba2c074dde.jpg?wh=1742x871)

LLM是一个非常特殊的模型，它的核心能力是 **阅读理解**——结合预训练集中的语料，根据提示词中提供的上下文信息执行任务。从概念上说，当我们为LLM提供了上下文之后，实际已经把 **LLM迁移成为一个面向特定领域的模型了**。

回想一下我们在 [开篇词](https://time.geekbang.org/column/article/757007) 中提过的例子：

```plain
目前我们在编写一个产品目录服务，通过API提供所有可售商品的详细信息；
此API包含列出所有商品，按SKU查看某个商品，按照分类列出商品以及按关键词搜索的功能；
API返回的结果是json格式；
当查找的SKU不存在时，返回404；
按关键搜索功能使用POST而不是GET；
使用Java编写；
为所有功能提供功能测试，包括异常情况。
请编写功能和测试代码。

```

这其中包含了 **上下文描述** 和 **问题/任务** 两个部分：

```plain
目前我们在编写一个产品目录服务，通过API提供所有可售商品的详细信息；(业务上下文)
此API包含列出所有商品，按SKU查看某个商品，按照分类列出商品以及按关键词搜索的功能；（业务功能描述）
API返回的结果是json格式；(技术规范描述）
当查找的SKU不存在时，返回404；(技术规范描述）
按关键搜索功能使用POST而不是GET；（最佳实践）
使用Java编写；（技术栈）
为所有功能提供功能测试，包括异常情况；（代码范围）
请编写功能和测试代码。（问题/任务）

```

在概念上，如果将提示词中的上下文与问题当作截然不同的两个部分，那么实际上我们可以将结合了上下文的LLM看作一个经过迁移学习后的模型：

![](https://static001.geekbang.org/resource/image/77/b4/772c489a62248ac2df6efc3bc27e46b4.jpg?wh=1694x906)

之所以可以这样看待大模型，是因为LLM在大规模数据集上进行预训练，能够学习到语言的深层结构和模式，因此具备了很强的 **泛化能力**。

这意味着LLM可以很容易地适应新的任务和领域，即使这些任务和领域在预训练时没有明确地被考虑进去。伴随着泛化能力，目前很多LLM支持 **零样本（zero-shot）或少样本（few-shot）学习**。这意味着即使没有数据训练，或者只有很少的数据的情况下，LLM也可以执行特定任务。

零样本或少样本学习是一种 **革命性的迁移学习机制**。比起传统迁移学习，训练数据从几千几万条降低到零或几条。训练时间从几天、几周甚至几个月缩短到几秒钟或者几分钟。

我们在提示词中对于上下文的描述，实际上是在使用 **零样本学习对LLM进行迁移学习训练。** 将LLM看作一种特殊的迁移学习（Transfer Learning）平台是通过LLM提取知识的关键，提醒我们需要将用以迁移的上下文和具体的任务分开来看待。

## 聚焦于知识而非任务

请你回想一下我们在开篇词中提到的例子，它最开始的版本是这样的：

```plain
目前我们在编写一个产品目录服务，通过API提供所有可售商品的详细信息。此API不能修改或增加可售商品。使用Java编写。
请提供代码和所有功能的功能测试。

```

在这个提示词中，主要描述的是 **任务本身**，也就是我们希望LLM帮助我们做什么，对于上下文和知识的描述是非常粗略的。此刻我们的关注点聚焦在LLM能做什么，寄希望于大模型的预训练 **恰好能够帮助我们补足上下文。**

这其实是过往时代和经验带来的局限， **我们习惯性地认为，将某个工作实际做出来是非常花费时间的，那么越早开始越好**。但是在LLM时代，做出来的成本是非常低的， **做对的成本是非常高的**。因而， **用好LLM的第一步，就是聚焦于知识的提取与组织。**

我们可以把要做的事情放在一边，将目光更多的集中在 **如何迁移训练LLM**，也就是如何提取上下文、如何提取知识上。那么我们可以构造这样的一个提示词：

```plain
背景
===
目前我们在编写一个产品目录服务，通过API提供所有可售商品的详细信息。
此API不能修改或增加可售商品。
使用Java编写。

任务
===
请问这个产品目录服务主要有什么功能？

```

我建议所有人在使用提示词的时候，都将知识的部分（背景）与任务的部分分开。这样能有一个明确的关注点。在这个改版的提示词中，我们暂时放弃了最终目标，而首先检查我们的知识提取是否足够清楚。ChatGPT给我的答案是：

![](https://static001.geekbang.org/resource/image/7b/6d/7bbc5d1d76d9856e9286af849a01546d.jpg?wh=1596x1531)

显然，这个答案与我预期的结果是不同的，我们预期中这个API只有列出所有商品、按SKU查看某个商品、按照分类列出商品以及按关键词搜索的功能。ChatGPT列出了非常多的额外功能。如果在这个基础上去生产代码，就会有很多无用的功能。

那这说明什么呢？ **说明迁移学习的效果并不好，LLM仍然受基础模型的影响，并没有完全迁移到我们现在要处理的领域。** 我们需要补充额外的信息，让LLM更接近我们要处理的领域。

我们可以补充这部分信息，然后使用同样的问题，再次询问LLM：

```plain
背景
===
目前我们在编写一个产品目录服务，通过API提供所有可售商品的详细信息。
此API包含列出所有商品，按SKU查看某个商品，按照分类列出商品以及按关键词搜索的功能；
使用Java编写。

任务
===
请问这个产品目录服务主要有什么功能？

```

![](https://static001.geekbang.org/resource/image/48/3e/486311788930f3da305926d7e9a6123e.jpg?wh=1544x1421)

这一次因为我们明确了功能的范围，ChatGPT给出的答案就完全符合我们的要求了。同样，我们还可以继续验证当前的业务知识是否是足够的，比如：

```plain
背景
===
目前我们在编写一个产品目录服务，通过API提供所有可售商品的详细信息。
此API包含列出所有商品，按SKU查看某个商品，按照分类列出商品以及按关键词搜索的功能；
使用Java编写。

任务
===
请问通过API提供的产品信息都包含哪些内容？

```

![](https://static001.geekbang.org/resource/image/78/95/783788c80d571d29765edd24dyyfdb95.jpg?wh=1631x2302)

同样ChatGPT提供了非常多的额外信息。如果在这个基础上去生产代码，还是会有很多无用的功能。因为我们这里是个例子，并没有细扣其中的具体实现细节，但是在实际工作中，我们可能会根据实际的情况，补充更完备的信息，比如：

```plain
背景
===
目前我们在编写一个产品目录服务，通过API提供所有可售商品的详细信息。
商品详细信息包括：SKU，商品名字，不同的产品选项，以Markdown形式保存的商品详情；
此API包含列出所有商品，按SKU查看某个商品，按照分类列出商品以及按关键词搜索的功能；
使用Java编写。

任务
===
请问通过API提供的产品信息都包含哪些内容？

```

当我们把目标聚焦于知识时，我们所关注的就不再仅仅是通过LLM帮助完成某些功能，而是如何使用LLM高质量地完成某些功能。

## 通过LLM提取与传递知识

这种通过LLM的反馈反思并修改知识描述的方式，就是知识工程中的 **知识提取流程**，你可以结合下图来理解。

![](https://static001.geekbang.org/resource/image/e9/72/e971c672db26bef0edc6713648f4ba72.jpg?wh=1537x787)

回想一下刚刚的例子，我们提取的是什么知识呢？我们提取的是隐式知识（Implicit Knowledge）。因为对于业务的上下文我们已经有了构想和要求，只不过没有变成文字形式而已。

在提取了隐式知识之后，我们就可以在提取的知识之上，完成不同的任务了。这时候我们的关注点又 **从知识重新回到了任务**。但此时我们会发现，提取出的知识并不仅仅能服务于某一项任务。在上面的例子里，虽然我们是为了编写代码而做的知识提取，但是产生的结果可以服务于其他任务。比如，为API编写文档：

```plain
背景
===
目前我们在编写一个产品目录服务，通过API提供所有可售商品的详细信息。
商品详细信息包括：SKU，商品名字，不同的产品选项，以Markdown形式保存的商品详情；
此API包含列出所有商品，按SKU查看某个商品，按照分类列出商品以及按关键词搜索的功能；
使用Java编写。

要求
===
所有API文档需要以RAML形式编写;
如存在异常分支，给出示例;

任务
===
根据背景中描述的业务，按要求编写文档

```

**当我们完成了知识提取，再将知识应用到具体的任务时，就是知识的传递和应用的过程**。在知识工程中，知识的提取与传递流程如下图所示：

![](https://static001.geekbang.org/resource/image/6e/b6/6e36412fe0d123e279c5f05ff5294fb6.jpg?wh=1847x1080)

## 小结

今天我们介绍了为什么要将LLM看作一个迁移学习平台，这样我们就可以将提示词中的上下文和任务赋予不同的意义。上下文负责迁移学习，而任务是要进行的操作。

然后我们沿用了开篇词里产品目录服务的例子，演示了如何提取上下文、如何提取知识。这里的重点是我们要聚焦在知识而非任务上，通过LLM来检验知识的收集与提炼是否充分。再把提取的知识与任务结合，完成知识的传递与应用。

通过LLM的辅助，利用知识与任务的分离，我们有效地收集和传递了显式化的隐式知识。但是对于知识过程中的核心——不可言说知识要怎么处理呢？我们下节课再继续讨论。

## 思考题

这节课例子演示了如何利用LLM提取隐式知识，那么对于不可言说知识，我们要怎么提炼和应用呢？

欢迎在留言区分享你的想法，我会让编辑置顶一些优质回答供大家学习讨论。