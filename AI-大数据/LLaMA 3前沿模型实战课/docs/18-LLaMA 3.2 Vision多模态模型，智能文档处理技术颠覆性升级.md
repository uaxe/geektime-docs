你好，我是Tyler！

上节课我们学习如何用LLaMA 3设计一个多智能体，你掌握的如何？这节课我们开始探索一些前沿技术，比如 LLaMA 3.2 Vision 多模态大模型，我们终于获得了一个在开源社区可用的，效果和稳定性得到保障的，并扩展了对视觉数据支持的专业大模型了。

作为一个开源且性能卓越的大模型，它不仅延续了 LLaMA 系列的稳定性和强大表现，还扩展了对视觉数据的深度支持。这使得它在多模态应用场景中具备了广泛的适用性，尤其在 **多模态 RAG**（Retrieval-Augmented Generation） 和 **IDP**（Intelligent Document Processing）这两个领域中，展示了巨大的潜力。

在实际应用中，LLaMA 3.2 Vision 为图像解析、复杂文档处理以及与其他多模态模型的协作能力带来了显著提升。例如，它可以高效识别图像中的关键信息，将其转化为语义化的输入，进一步提升下游任务的完成效果。同时，结合现有的 RAG 技术，它能够将图像、文本和结构化数据无缝集成，为知识检索和生成提供更为全面的支持。

### 部署与初体验：Ollama 轻松实现模型调用

值得一提的是，这款模型在部署上延续了以往的便捷性。我们可以借助熟悉的工具 Ollama 来完成部署和集成。LLaMA 3.2 Vision 模型延续了 Ollama 提供的简洁部署和调用体验。开发者只需通过以下命令，即可快速启动模型并开始使用：

```python
ollama run x/llama3.2-vision:11b

```

下面我将详细介绍如何结合 Ollama 调用模型进行图像智能分析，我们可以通过 Ollama 提供的 chat 接口调用 LLaMA 3.2 Vision 模型，并结合提示词（prompt）实现智能分析。以下是示例代码：

```python
import ollama

response = ollama.chat(
    model='llama3.2-vision',
    messages=[{
        'role': 'user',
        'content': 'What is in this image?',
        'images': ['image.jpg']
    }]
)

print(response)

```

通过以上代码，开发者可以轻松完成从图像文件到模型输出的一站式操作。Ollama 提供了强大的灵活性，结合 LLaMA 3.2 Vision 模型的能力，使得处理复杂的多模态任务变得简单高效。

### 为什么说 LLaMa3.2 Vision 具备了视觉能力？

那么问题来了，LLaMA 3.2 Vision 是怎么做到这些的？它的核心在于 **全新的架构设计和训练流程**。Meta 的技术报告提到，这款模型的构建在原来的 LLaMA 3.1 文本模型基础上新增了一套视觉适配器（adapter）。这些适配器通过跨注意力机制，把图像编码器的输出嵌入到语言模型中。也就是说，图像和文本的数据流可以在模型内部深度融合，形成完整的多模态表示。

具体来说，这个模型的训练过程分为几个阶段。首先，它用大规模的图像-文本配对数据进行预训练，建立图像表示和语言表示之间的初步关联。接着，模型会用更高质量的领域数据微调，使得它在特定场景下的表现更加精准。最后，还通过监督微调、安全性优化和偏好调整等方法，进一步提升了模型的表现能力和安全性。

这一系列优化确保了 LLaMA 3.2 Vision 不仅能处理复杂的多模态任务，还在使用中保持高效和安全。更值得一提的是，尽管模型新增了视觉能力，但它并没有影响原有的语言处理性能。对于开发者来说，这意味着你可以直接把它当作 LLaMA 3.1 的替代品来用，完全不用担心兼容性问题。

![](https://static001.geekbang.org/resource/image/fa/fb/fa068e15305a9dedf09b03447dc42afb.png?wh=869x972)

LLaMA 3.2 Vision 的发布，标志着多模态大模型迈出了重要一步。无论是知识检索、复杂文档处理，还是图像和文本结合的任务，它都能提供前所未有的支持。对于开源社区来说，这不仅是一次技术创新，更是一次实用性和普及性的重大突破。

### 应用场景：多模态文档的智能解析

LLaMA 3.2 Vision 模型在复杂文档解析中的表现尤为出色。接下来我列举几个典型应用场景，展示一下如何将模型应用于实际业务中。

1. PPT 和表格解析

在企业日常中，PPT 和表格是信息承载的重要形式。借助 LLaMA 3.2 Vision 模型，开发者可以直接将 PPT 或表格的截图作为输入，并通过简单的提示词（prompt）生成精准的自然语言总结。

示例操作：输入一张 PPT 页面截图，并使用以下提示词：

```plain
Summarize the image, preserving essential facts and figures.

```

输出结果将包含 PPT 页面中的关键信息，如标题、关键数据或图表描述。这里有一个小 Trick，那就是在解析 PPT 文档的时候，我们可以先把它转化为一个 PDF，以便后续处理。

2. PDF 文档处理

PDF 格式是文档存储的主流形式，尤其在合同、报告、研究文献等复杂文档中，视觉内容（如图表、照片）往往是重要的信息来源。然而，传统的文本模型无法直接处理这些视觉数据。通过 LLaMA 3.2 Vision 模型，可以实现从 PDF 图像到结构化信息的自动化转换。

**PDF 转图片代码示例**：

```python
from pdf2image import convert_from_path

# 将 PDF 转换为图像
images = convert_from_path('example.pdf')

# 保存每页图像
for i in range(len(images)):
    images[i].save('page' + str(i) + '.jpg', 'JPEG')

```

在提取出图像后，开发者可以结合上述 Base64 转换和模型调用方法，完成图像内容的智能分析，并将提取结果作为 RAG 系统的输入。

3. 多模态知识库构建

多模态知识库构建是RAG的重要方向。通过 LLaMA 3.2 Vision 模型，可以统一处理多种形式的信息（如文档、图片、表格等），将其解析为结构化文本数据，便于后续的检索与生成任务。

### LLaMA 3.2 Vision 🆚 OCR：IDP 的颠覆性技术升级

LLaMA 3.2 Vision 模型的推出，让我们看到了智能文档处理（IDP，Intelligent Document Processing）技术的新可能。与传统 OCR 技术相比，它不只是一次工具迭代，而是 AI 在多模态数据解析领域的一次变革。下面，我们将从关键特性和实际价值两个层面展开分析。

![图片](https://static001.geekbang.org/resource/image/08/4f/084fc7536ff7b6bc9e91f016124a644f.png?wh=1920x1268)

![图片](https://static001.geekbang.org/resource/image/6f/14/6f874bbea2b159f50685ca0face5e914.png?wh=1920x916)

![图片](https://static001.geekbang.org/resource/image/88/44/8822bba6d3de03f8de32e887940dc744.png?wh=1920x947)

LLaMA 3.2 Vision 能够直接处理图片数据，理解其内容并生成自然语言描述。相较于 OCR，它具备更强的泛化能力。因此，LLaMA 3.2 Vision 的发布不仅仅是一次技术更新，它实际上对 IDP 技术的发展意义深远。

#### 什么是 IDP？

**IDP（Intelligent Document Processing，智能文档处理）** 是近年来迅速发展的一个重要领域，旨在通过 AI 技术对复杂文档进行高效、准确地解析和处理。

IDP 技术通常应用于企业自动化流程中，用来从非结构化或多模态文档中提取有价值的信息，其核心需求包括：

1. **处理复杂文档结构**：许多文档（如 PDF、表格、PPT）不仅包含文本，还包括图片、图表等复杂内容。

2. **高准确性和鲁棒性**：文档内容的多样性（如语言、格式、清晰度）要求系统具备强大的泛化能力。

3. **多模态支持**：传统技术（如 OCR）主要处理文本，但 IDP 需要支持图像、表格、手写体等多模态数据。

4. **高效处理海量数据**：面对企业级应用场景，IDP 系统需要高效处理大规模文档。


LLaMA 3.2 Vision 模型正是为了解决上述 IDP 核心需求而生，以下几点是其成为 IDP 重要技术的原因：

1. **多模态解析能力**：传统的 IDP 系统大多依赖 OCR 模型来解析文本，而对于包含图表、结构化表格或手写体的内容，OCR 的表现往往不够理想。而 LLaMa 3.2 Vision 能够直接处理图片，并通过提示词灵活生成自然语言描述。

2. **从文档到知识的自动转化**：LLaMA 3.2 Vision 不仅能够提取文档中的信息，还能将提取的内容进行语义理解，并转化为可用于知识库构建的结构化信息。相比传统的 OCR + NLP 联合处理，Vision 模型通过一步到位的方式大大简化了流程。

3. **减少预处理与调优成本**：OCR 模型的使用通常需要针对特定文档类型或语言进行复杂的调优（例如训练模型以适配表格布局或特定字体），而 LLaMA 3.2 Vision 的泛化能力使其能够直接处理各种类型的文档，几乎不需要额外的调优。开发者只需通过合适的提示词，即可灵活完成不同任务。


```plain
Describe the table in detail, including all key figures and relationships.

```

4. **扩展到复杂文档处理的可能性**：传统 IDP 系统在处理非结构化数据时，通常需要结合多种技术手段（如OCR、图像处理、知识图谱等）。而 LLaMA 3.2 Vision 模型可以作为一种通用技术，将图像理解与语言生成结合，显著提高 IDP 系统的能力。

例如，它可以直接解析以下内容：

- **合同或发票** 中的关键字段；
- **财务报表** 中的数字关系和趋势；
- **物流单据** 中的手写内容。
- …

5. **对大规模文档的高效处理**：LLaMA 3.2 Vision 11B 模型能够在更低的硬件要求下支持大规模文档解析。这对于需要批量处理海量数据的企业来说，显然具有非常高的价值。

### 总结

学到这里我们做个总结吧。LLaMA 3.2 Vision 模型以轻量化、高扩展性和强多模态解析能力，为多模态 RAG 的发展提供了新的可能。无论是高效解析 PPT 和表格，还是快速处理 PDF 文档，其简单的部署方式和强大的功能都为企业和开发者节省了大量时间和成本。

此外，随着企业对 IDP 的需求不断增长，LLaMA 3.2 Vision 模型为这一领域注入了全新的活力。它不仅提升了文档处理的效率，还降低了部署的复杂性。未来，随着模型与知识图谱、领域特定数据库等技术的进一步融合，IDP 系统有望实现更智能、更全面的自动化文档处理能力。

从更广的视角来看，LLaMA 3.2 Vision 模型不仅是 IDP 技术的突破点，更是多模态 AI 社区发展的重要里程碑。它为多模态技术的应用场景提供了丰富的可能性，也为企业解锁了更多自定义开发的能力和自由度，可以基于此构建内部的 IDP 智能化的业务流程。

### 思考题

1. 为什么说 LLaMA 3.2 Vision 的能力比 OCR 要更适合 IDP 任务？

2. 你还能想到哪些 LLaMA 3.2 Vision 的应用场景？


欢迎你把你的思考分享到评论区，也欢迎你把这节课的内容分享给其他朋友，我们下节课再见！